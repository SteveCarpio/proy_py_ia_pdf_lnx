import streamlit as st

# ----------------------------------------
# EJECUCI√ìN PRINCIPAL
# ----------------------------------------
def main():

    import streamlit as st
    import PyPDF2
    import ollama
    import pandas as pd
    import time

    # CONFIGURACI√ìN
    st.set_page_config(page_title="üìë Analizador de Contratos IA", layout="wide")
    MODEL = "gpt-oss:20b" #  llama3:instruct | jobautomation/OpenEuroLLM-Spanish | gpt-oss:20b

    # ---------------------------
    # FUNCIONES
    # ---------------------------

    def cargar_pdf(uploaded_file, max_paginas=50):
        reader = PyPDF2.PdfReader(uploaded_file)
        contenido_paginas = []

        for i, page in enumerate(reader.pages[:max_paginas]):
            text = page.extract_text()
            if text:
                contenido_paginas.append((i + 1, text))

        return contenido_paginas

    def dividir_en_bloques(paginas, tama√±o_bloque=10):
        bloques = []
        for i in range(0, len(paginas), tama√±o_bloque):
            bloque = paginas[i:i + tama√±o_bloque]
            texto_bloque = "\n\n".join([f"[P√°gina {p}] {t}" for p, t in bloque])
            bloques.append((bloque[0][0], bloque[-1][0], texto_bloque))
        return bloques

    def preguntar_al_modelo_streaming(prompt):
        respuesta = ""
        try:
            response = ollama.chat(
                model=MODEL,
                messages=[{"role": "user", "content": prompt}],
                stream=True
            )
            for chunk in response:
                chunk_text = chunk.get('message', {}).get('content', '')
                respuesta += chunk_text
                yield chunk_text
        except Exception as e:
            yield f"‚ùå Error al generar respuesta: {str(e)}"

    # ---------------------------
    # SESIONES
    # ---------------------------

    if "analisis_bloques" not in st.session_state:
        st.session_state.analisis_bloques = []

    if "contenido_pdf" not in st.session_state:
        st.session_state.contenido_pdf = []

    if "chat" not in st.session_state:
        st.session_state.chat = []

    # ---------------------------
    # INTERFAZ
    # ---------------------------

    st.title("üìÑ Analizador de Contratos con IA")
    st.caption("Sube un contrato en PDF (m√°ximo 50 p√°ginas). IA buscar√° art√≠culos sobre fideicomisos y f√≥rmulas.")

    uploaded_file = st.file_uploader("üîΩ Sube un archivo PDF", type=["pdf"])

    if uploaded_file:
        with st.spinner("üìñ Leyendo y dividiendo el contrato en bloques..."):
            contenido = cargar_pdf(uploaded_file, max_paginas=50)
            bloques = dividir_en_bloques(contenido, tama√±o_bloque=10)
            st.session_state.contenido_pdf = contenido
            st.session_state.analisis_bloques = []

        st.success("‚úÖ Archivo cargado correctamente. Comienza el an√°lisis...")

        for idx, (inicio, fin, bloque) in enumerate(bloques):
            with st.expander(f"üßæ Bloque {idx + 1} (P√°ginas {inicio}-{fin})", expanded=False):
                consulta = f"""
    Tengo un contrato legal. Quiero que busques en el siguiente texto todos los art√≠culos o secciones que hagan referencia a cualquier tipo de "reserva de fideicomisos".

    Para cada art√≠culo encontrado, devu√©lveme:
    1. El n√∫mero o nombre del art√≠culo
    2. La p√°gina (si la menciono en el texto que te doy)
    3. Un resumen en 1 sola frase de qu√© trata ese art√≠culo

    Adem√°s, si el art√≠culo contiene una f√≥rmula o ecuaci√≥n:
    - Extrae la f√≥rmula exacta
    - Explica el significado de cada variable o constante
    - Devu√©lvelo en una tabla con columnas: Art√≠culo, F√≥rmula, Variable, Definici√≥n

    Respode siempre en ESPA√ëOL.

    Texto del contrato (p√°ginas {inicio}-{fin}):

    {bloque}
    """

                output_placeholder = st.empty()
                full_output = ""

                with st.status("ü§ñ Analizando bloque con IA..."):
                    for chunk in preguntar_al_modelo_streaming(consulta):
                        full_output += chunk
                        output_placeholder.markdown(full_output)

                st.session_state.analisis_bloques.append(full_output)

        st.markdown("---")

    # ---------------------------
    # MODO CHAT IA
    # ---------------------------

    if st.session_state.contenido_pdf:
        st.subheader("üí¨ Haz preguntas sobre el contrato")

        for msg in st.session_state.chat:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        pregunta = st.chat_input("¬øQu√© quieres preguntar sobre el contrato?")

        if pregunta:
            with st.chat_message("user"):
                st.markdown(pregunta)
            st.session_state.chat.append({"role": "user", "content": pregunta})

            # Unimos el contenido de las p√°ginas cargadas (limitado a 50)
            contexto = "\n\n".join([f"[P√°gina {p}] {t}" for p, t in st.session_state.contenido_pdf])

            prompt_chat = f"""Este es el contenido parcial de un contrato legal en espa√±ol:

    {contexto}

    Pregunta del usuario: {pregunta}
    """

            with st.chat_message("assistant"):
                placeholder = st.empty()
                full_response = ""
                with st.status("üß† Pensando..."):
                    for chunk in preguntar_al_modelo_streaming(prompt_chat):
                        full_response += chunk
                        placeholder.markdown(full_response)

            st.session_state.chat.append({"role": "assistant", "content": full_response})

