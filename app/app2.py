import streamlit as st

def main():
    import streamlit as st
    from io import BytesIO # Importaci√≥n de BytesIO para manejar archivos en memoria
    import tempfile # Importaci√≥n de la librer√≠a temporal para crear directorios temporales
    import os  # Importaci√≥n de la librer√≠a para operaciones de sistema (manejo de archivos y directorios)
    import json  # Importaci√≥n de la librer√≠a para trabajar con datos en formato JSON
    from vosk import Model, KaldiRecognizer  # Importaci√≥n de las clases necesarias para el reconocimiento de voz
    import wave  # Librer√≠a para trabajar con archivos WAV
    from pydub import AudioSegment  # Librer√≠a para convertir y manipular audios
    import requests  # Librer√≠a para realizar solicitudes HTTP
    import re  # Importaci√≥n de la librer√≠a para expresiones regulares
    import ollama # Importaci√≥n de la librer√≠a Ollama para interactuar con modelos de IA
    import shutil # Importaci√≥n de la librer√≠a para copiar archivos y directorios
    from datetime import datetime # Importaci√≥n de la clase datetime para manejar fechas y horas
    import time  # Importaci√≥n de la librer√≠a para manejar el tiempo

    # Configuraci√≥n de la librer√≠a pydub para usar ffmpeg
    AudioSegment.converter = "/usr/bin/ffmpeg"
    AudioSegment.ffprobe = "/usr/bin/ffprobe"

    ######################################################################################################################
    ### FUNCIONES VARIAS
    ######################################################################################################################

    ### Funci√≥n: convert_to_wav ##########################################################################
    # Objetivo: Convertir cualquier archivo de audio a formato WAV con un solo canal y frecuencia de 16000
    def convert_to_wav(audio_path):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # Cargar el archivo de audio y convertirlo a formato WAV con las configuraciones especificadas
        sound = AudioSegment.from_file(audio_path)
        sound = sound.set_channels(1).set_frame_rate(16000) # Configura el canal mono y la frecuencia de muestreo
        wav_path = f"temp_{timestamp}.wav"
        sound.export(wav_path, format="wav") # Exportar el audio convertido
        return wav_path

    ### Funci√≥n: save_txt ###############################################
    # Objetivo: Guardar el texto transcrito en un archivo de texto (.txt)
    def save_txt(text, path):
        with open(path, "w", encoding="utf-8") as f:
            f.write(text) # Escribir el texto en el archivo especificado

    ### Funci√≥n: transcribe ##############################################################
    # Objetivo: Transcribir el audio (en formato WAV) a texto utilizando el modelo de Vosk
    def transcribe(audio_path, model_path, timestamp):
        # Convertir el audio de entrada a formato WAV
        wav_path = convert_to_wav(audio_path)
        # Cargar el modelo preentrenado de Vosk

        model = Model(model_path)
        results = [] # Lista para almacenar las transcripciones

        # Abrir el archivo WAV y preparar el reconocimiento de voz
        with wave.open(wav_path, "rb") as wf:
            rec = KaldiRecognizer(model, wf.getframerate())
            while True:
                # Leer datos del archivo WAV en bloques de 4000 frames
                data = wf.readframes(4000)
                if len(data) == 0: # Si no hay m√°s datos, salir del bucle
                    break
                if rec.AcceptWaveform(data): # Si el bloque de audio es aceptado por el reconocedor
                    # Solo texto puro
                    result_json = json.loads(rec.Result()) # Parsear la transcripci√≥n en formato JSON
                    results.append(result_json.get("text", "")) # Guardar el texto transcrito
            # Obtener el resultado final de la transcripci√≥n
            final_json = json.loads(rec.FinalResult())
            results.append(final_json.get("text", "")) # Guardar el texto final

        # Copiar y Eliminar el archivo temporal
        shutil.copy(wav_path, f'{ruta_salida}/Audio_{timestamp}_convertido.wav')  # Copiar el archivo WAV a la ruta de salida
        os.remove(wav_path)
        
        # Unir todas las transcripciones y devolverlas como un √∫nico texto
        return "\n".join(results).strip() 

    ### Funci√≥n: procesar_audio ################################################
    # Objetivo: Transcribir el audio y luego generar un resumen utilizando la IA
    def procesar_audio(audio_file, modelo_dir, base, timestamp):
        # Llamar a la funci√≥n de transcripci√≥n para obtener el texto del audio
        texto = transcribe(audio_file, modelo_dir, timestamp)
        # Guardar el texto transcrito en un archivo .txt
        txt_path = f"{base}/Audio_{timestamp}_texto_completo.txt"
        save_txt(texto, txt_path)
        return texto, txt_path


    ### Funci√≥n: resumir_ollama #########################################################################
    # Objetivo: Generar un resumen profesional de la reuni√≥n usando un modelo de IA (por ejemplo, Ollama)
    def resumir_ollama(texto, modelo_ollama, base, timestamp, seleccion):

        if seleccion == "Reuni√≥n":
            prompt = (
                "A continuaci√≥n tienes la transcripci√≥n de una reuni√≥n en espa√±ol, posiblemente sin puntuaci√≥n ni formato. "
                "Tu tarea es redactar un acta profesional de la reuni√≥n, respetando el idioma espa√±ol.\n\n"
                "Por favor, sigue estas instrucciones:\n"
                "- Indica la fecha, hora y lugar de la reuni√≥n (si esos datos aparecen en el texto; si no, deja un espacio para completarlos).\n"
                "- Presenta una breve descripci√≥n de los participantes, indicando nombre completo y, si es posible, su empresa o rol.\n"
                "- Haz un listado breve y claro de los puntos tratados en la reuni√≥n.\n"
                "- Si quedan temas pendientes o para la pr√≥xima reuni√≥n, ind√≠calos como 'Puntos pendientes'.\n"
                "- Mant√©n una redacci√≥n clara, profesional y estructurada.\n\n"
                f"Transcripci√≥n de la reuni√≥n:\n\n{texto}\n\n"
            )

        if seleccion == "Conversaci√≥n":
            prompt = (
                "A continuaci√≥n tienes la transcripci√≥n de una conversaci√≥n, posiblemente sin puntuaci√≥n ni formato. "
                "Tu tarea es redactar un resumen de la conversaci√≥n, si la conversaci√≥n no est√° en espa√±ol lo traduces y lo colocas abajo de la linea original.\n\n"
                "Al final debes poner la Transcripci√≥n de la conversaci√≥n con un titulo\n"
                "Todo debe quedar con una estructura clara, profesional y estructurada.\n\n"
                f"Transcripci√≥n de la conversaci√≥n:\n\n{texto}\n\n"
            )

        try:
            respuesta = ollama.chat(
                model=modelo_ollama,
                messages=[{"role": "user", "content": prompt}]
            )
            resumen = respuesta['message']['content'].strip()
        except Exception as e:
            raise RuntimeError(f"Error al generar el resumen con el modelo '{modelo_ollama}': {e}")

        resumen_filename = f"Audio_{timestamp}_texto_resumen.txt"  #  f"resumen_{timestamp}.txt"
        resumen_path = os.path.join(base, resumen_filename)

        try:
            os.makedirs(base, exist_ok=True)  # Asegura que el directorio exista
            with open(resumen_path, 'w', encoding='utf-8') as f:
                f.write(resumen)
        except Exception as e:
            raise IOError(f"No se pudo guardar el archivo de resumen en {resumen_path}: {e}")

        return resumen, resumen_path

    # Leer el archivo .txt para mostrarlo en la WEB
    @st.cache_data
    def load_markdown_file(file_path):
        with open(file_path, "r", encoding="utf-8") as file:
            return file.read()

    ######################################################################################################################
    ### INICIO DEL PROGRAMA
    ######################################################################################################################

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # Configuraci√≥n inicial de la app
    #st.set_page_config("(TDA) Lector de Facturas IA", layout="wide")
    st.title("ü§ñ Transcripci√≥n de Audio")  # üóÇÔ∏è üìÑ  ü§ñ
    st.caption("Combina ASR (Reconocimiento Autom√°tico de Voz) con modelos LLM para transformar audio en texto estructurado y res√∫menes contextuales.")

    # Crear directorio temporal para subidas
    UPLOAD_FOLDER = os.path.join(tempfile.gettempdir(), "transcripcion_audio")
    os.makedirs(UPLOAD_FOLDER, exist_ok=True)

    st.sidebar.markdown("---")  # Separador

    # Opci√≥n 2: Subida de archivos desde el cliente
    uploaded_files = st.sidebar.file_uploader(
        label="üìÅ Seleccione Archivo AUDIO  ",  
        type=["mp3", "wav", "ogg"],
        accept_multiple_files=False,
        label_visibility="visible" 
    )

    # Procesar archivos subidos
    folder = "/home/robot/Python/x_audios"
    if uploaded_files:      
        st.sidebar.success(f"‚úÖ Se subio correctamente")
        folder = UPLOAD_FOLDER  # Usar la carpeta de subidas para procesamiento
        # Visualizar el reproductor del audio para escuchar el audio 
        file_path = os.path.join("/tmp/transcripcion_audio/", uploaded_files.name)
        with open(file_path, "wb") as f:
            f.write(uploaded_files.getbuffer())
        st.audio(uploaded_files, format=uploaded_files.type.split("/")[-1])
        
    # SelectBox para elegir el tipo de Audio
    opciones = ["Reuni√≥n", "Conversaci√≥n", "Canci√≥n", "Poema", "Otros"]  # lista de opciones
    seleccion = st.sidebar.selectbox(
        "Indique el tipo del audio:",
        opciones,
        index=0,               # √≠ndice por defecto (0 = primera opci√≥n)
        key="opcion_elegida"   # clave opcional para mantener estado
    )

    ############## BOT√ìN: para procesar AUDIO ##############
    if st.sidebar.button("Procesar AUDIO"):

        if uploaded_files is None:
            st.write("")
            st.write(" ‚ÑπÔ∏è Debe seleccionar un fichero de audio y luego darle a 'Procesar AUDIO'")

        else:
            ############## INICIO DEL PROCESAMIENTO ##############

            with st.spinner(f'Tipo {seleccion}: Por favor espere...'):

                nombre_audio = f'Audio_{timestamp}'

                # Si se sube el archivo a la carpeta temporal de Linux
                if uploaded_files is not None:
                    extension = os.path.splitext(uploaded_files.name)[1]
                    os.rename(file_path, file_path.replace(uploaded_files.name, f'{nombre_audio}_original{extension}'))

                # Obtener IP del cliente si est√° disponible
                client_ip = st.context.ip_address  # solo disponible en v1.45.0+
                if client_ip:
                    access_time = datetime.now().strftime("%Y-%m-%d > %H:%M:%S")
                    with open("/home/robot/Python/x_log/streamlit_ip.log", "a") as f:
                        f.write(f"{access_time} > {client_ip} > Pag2 > IA_Transcripcion_Audio (new) >> {nombre_audio}{extension} \n")

                audio_file = f"/tmp/transcripcion_audio/{nombre_audio}_original{extension}"
                modelo_dir  = "/opt/models/vosk/vosk-model-es-0.42"    
                modelo_ollama = "gpt-oss:20b"          #  [ llama3:instruct | mistral | gpt-oss:20b ]
                ruta_salida = "/tmp/transcripcion_audio"
                base = ruta_salida
                
                # Funci√≥n Procesar Audio
                texto, txt_path = procesar_audio(audio_file, modelo_dir, base, timestamp)  
                
                # Funci√≥n Crea Resumen Modelo IA
                resumen, resumen_path = resumir_ollama(texto, modelo_ollama, base, timestamp, seleccion)
                
                st.caption("üìù Resumen de la transcripci√≥n revisada por ChatTdA:")

                # Mostrar el texto2 transcrito en la WEB
                file_path2 = f"/tmp/transcripcion_audio/Audio_{timestamp}_texto_resumen.txt"  
                markdown_content = load_markdown_file(file_path2)
                st.markdown(markdown_content, unsafe_allow_html=False)

                st.markdown("---")

                st.caption("üìù Transcripci√≥n original del audio sin IA:")

                # Mostrar el texto1 transcrito en la WEB
                file_path1 = f"/tmp/transcripcion_audio/Audio_{timestamp}_texto_completo.txt"  
                markdown_content = load_markdown_file(file_path1)
                st.markdown(markdown_content, unsafe_allow_html=False)

                st.markdown("---")

            st.success("¬° Audio procesado y transcrito correctamente !")

    
